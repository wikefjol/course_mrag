{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/filbern/workspace/projects/course_mrag/venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading existing vectorstore for sources/book...\n",
      "Loading existing vectorstore for sources/lectures...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from src.dialogue_tools import create_rag, generate_answers, generate_follow_up_questions, cross_agent_verification, aggregate_final_response, organize_into_json, display_from_json\n",
    "from src.vectorstore import VectorstoreHandler\n",
    "from src.models import init_llm\n",
    "\n",
    "########################################\n",
    "# Configuration\n",
    "########################################\n",
    "SOURCES_DIR = \"sources\"\n",
    "JSON_PATH = \"multi_source_conversation.json\"\n",
    "AGGREGATION_LLM_NAME = \"Llama3.2-3b\"\n",
    "\n",
    "# Dynamically create one RAG config per subfolder under sources\n",
    "subfolders = [d for d in os.listdir(SOURCES_DIR) if os.path.isdir(os.path.join(SOURCES_DIR, d))]\n",
    "RAG_CONFIG = {}\n",
    "for sub in subfolders:\n",
    "    RAG_CONFIG[sub] = {\n",
    "        \"subfolder\": sub,\n",
    "        \"llm_name\": \"Llama3.2-3b\",\n",
    "        \"emb_name\": \"hf-minilm-l6-v2\",\n",
    "        \"k\": 10,\n",
    "    }\n",
    "\n",
    "handler = VectorstoreHandler(SOURCES_DIR, force_rebuild=False)\n",
    "rags = {name: create_rag(SOURCES_DIR, cfg, handler) for name, cfg in RAG_CONFIG.items()}\n",
    "aggregation_llm = init_llm(AGGREGATION_LLM_NAME)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Querying all RAGs for prompt: 'Explain how the kidneys regulate fluid and electrolyte balance. Include the processes of filtration, reabsorption, secretion, and excretion'\n",
      "================================================================================\n",
      "--- Querying RAG: book ---\n",
      "--- Querying RAG: lectures ---\n",
      "\n",
      "Querying all RAGs for prompt: 'The original question was:\n",
      "Explain how the kidneys regulate fluid and electrolyte balance. Include the processes of filtration, reabsorption, secretion, and excretion\n",
      "\n",
      "Here's the follow-up question:\n",
      "How do variations in ADH levels and individual differences in renal function affect the kidneys' ability to regulate fluid and electrolyte balance, and what are the consequences of dysregulation in these mechanisms?'\n",
      "================================================================================\n",
      "--- Querying RAG: book ---\n",
      "\n",
      "Querying all RAGs for prompt: 'The original question was:\n",
      "Explain how the kidneys regulate fluid and electrolyte balance. Include the processes of filtration, reabsorption, secretion, and excretion\n",
      "\n",
      "Here's the follow-up question:\n",
      "How do the kidneys utilize active transport mechanisms and ion channels in the renal tubules to facilitate reabsorption and secretion of ions, such as sodium and potassium, to maintain fluid and electrolyte balance?'\n",
      "================================================================================\n",
      "--- Querying RAG: lectures ---\n"
     ]
    }
   ],
   "source": [
    "# Example question\n",
    "original_prompt = \"Explain how the kidneys regulate fluid and electrolyte balance. Include the processes of filtration, reabsorption, secretion, and excretion\" \n",
    "\n",
    "########################################\n",
    "# 1) Ask each RAG for initial answer\n",
    "########################################\n",
    "initial_responses = generate_answers(original_prompt, rags)\n",
    "\n",
    "########################################\n",
    "# 2) Aggregation LLM -> follow-up question for each RAG\n",
    "########################################\n",
    "agent_answers = {rag_name: data[\"answer\"] for rag_name, data in initial_responses.items()}\n",
    "follow_up_questions = generate_follow_up_questions(aggregation_llm, original_prompt, agent_answers)\n",
    "\n",
    "########################################\n",
    "# 3) Each RAG answers its follow-up question\n",
    "########################################\n",
    "follow_up_responses = {}\n",
    "for agent_name, question in follow_up_questions.items():\n",
    "    # Each agent gets exactly one follow-up question\n",
    "    answers = generate_answers(question, {agent_name: rags[agent_name]})\n",
    "    follow_up_responses[agent_name] = answers[agent_name]\n",
    "\n",
    "########################################\n",
    "# 4) Cross-reference: pick one other RAG to verify each answer\n",
    "########################################\n",
    "# We'll do a round-robin: for agent i, use agent (i+1) mod len(rags) to verify\n",
    "\n",
    "rag_names = list(rags.keys())\n",
    "cross_input = {}\n",
    "for i, agent_name in enumerate(rag_names):\n",
    "    target_answer = follow_up_responses[agent_name]\n",
    "    # choose a verifying agent\n",
    "    verifier_name = rag_names[(i+1) % len(rag_names)]\n",
    "    cross_input.setdefault(agent_name, {})[verifier_name] = {\n",
    "        \"prompt\": original_prompt,\n",
    "        \"follow_up\": follow_up_questions[agent_name],\n",
    "        \"answer\": target_answer[\"answer\"],\n",
    "        \"docs\": target_answer[\"docs\"]\n",
    "    }\n",
    "\n",
    "cross_agent_responses = {}\n",
    "for target_rag, verifiers_dict in cross_input.items():\n",
    "    cross_agent_responses[target_rag] = {}\n",
    "    for verifier_rag, content in verifiers_dict.items():\n",
    "        # cross_agent_verification expects {rag_name: answer_dict}, so build minimal structure\n",
    "        cross_agent_responses[target_rag][verifier_rag] = cross_agent_verification(\n",
    "            {verifier_rag: rags[verifier_rag]},\n",
    "            {target_rag: content},\n",
    "            content[\"prompt\"],\n",
    "            {target_rag: content[\"follow_up\"]}\n",
    "        ).get(target_rag, {})\n",
    "\n",
    "########################################\n",
    "# 5) Final aggregated answer\n",
    "########################################\n",
    "all_responses = {}\n",
    "for agent_name in rags.keys():\n",
    "    all_responses[agent_name] = {\n",
    "        \"initial\": initial_responses[agent_name][\"answer\"],\n",
    "        \"follow_up\": follow_up_responses[agent_name][\"answer\"] if agent_name in follow_up_responses else \"\",\n",
    "    }\n",
    "\n",
    "final_answer = aggregate_final_response(aggregation_llm, all_responses, original_prompt)\n",
    "\n",
    "########################################\n",
    "# 6) Organize results in JSON and display\n",
    "########################################\n",
    "conversation_json = organize_into_json(\n",
    "    original_prompt,\n",
    "    initial_responses,\n",
    "    follow_up_questions,\n",
    "    follow_up_responses,\n",
    "    final_answer\n",
    ")\n",
    "conversation_json[\"cross_agent_responses\"] = {\n",
    "    target_rag: {\n",
    "        verifier: resp.get(\"answer\", \"No answer\")\n",
    "        for verifier, resp in cross_agent_responses[target_rag].items()\n",
    "    }\n",
    "    for target_rag in cross_agent_responses\n",
    "}\n",
    "\n",
    "#display_from_json(conversation_json)\n",
    "json.dump(conversation_json, open(JSON_PATH, \"w\"), indent=2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
